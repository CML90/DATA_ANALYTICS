{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7873b43f",
   "metadata": {},
   "source": [
    "Caitlin Lindsay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07ae4d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kmodes in c:\\users\\cait\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\cait\\anaconda3\\lib\\site-packages (from kmodes) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\cait\\anaconda3\\lib\\site-packages (from kmodes) (1.4.2)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\cait\\anaconda3\\lib\\site-packages (from kmodes) (1.13.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\cait\\anaconda3\\lib\\site-packages (from kmodes) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\cait\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.0->kmodes) (2.2.0)\n",
      "Requirement already satisfied: ucimlrepo in c:\\users\\cait\\anaconda3\\lib\\site-packages (0.0.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cait\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\cait\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\cait\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\cait\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\cait\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install kmodes\n",
    "!pip install ucimlrepo\n",
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05b12bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import fowlkes_mallows_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb78aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 91, 'name': 'Soybean (Small)', 'repository_url': 'https://archive.ics.uci.edu/dataset/91/soybean+small', 'data_url': 'https://archive.ics.uci.edu/static/public/91/data.csv', 'abstract': \"Michalski's famous soybean disease database\", 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 47, 'num_features': 35, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1980, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C5DS3P', 'creators': ['R. Michalski'], 'intro_paper': None, 'additional_info': {'summary': 'A small subset of the original soybean database.  See the reference for Fisher and Schlimmer in soybean-large.names for more information.\\r\\n    \\r\\nSteven Souders wrote:\\r\\n\\r\\n    > Figure 15 in the Michalski and Stepp paper (PAMI-82) says that the\\r\\n    > discriminant values for the attribute CONDITION OF FRUIT PODS for the\\r\\n    > classes Rhizoctonia Root Rot and Phytophthora Rot are \"few or none\"\\r\\n    > and \"irrelevant\" respectively.  However, in the SOYBEAN-SMALL dataset\\r\\n    > I got from UCI, the value for this attribute is \"dna\" (does not apply)\\r\\n    > for both classes.  I show the actual data below for cases D3\\r\\n    > (Rhizoctonia Root Rot) and D4 (Phytophthora Rot).  According to the\\r\\n    > attribute names given in soybean-large.names, FRUIT-PODS is attribute\\r\\n    > #28.  If you look at column 28 in the data below (marked with arrows)\\r\\n    > you\\'ll notice that all cases of D3 and D4 have the same value.  Thus,\\r\\n    > the SOYBEAN-SMALL dataset from UCI could NOT have produced the results\\r\\n    > in the Michalski and Stepp paper.\\r\\n\\r\\nI do not have that paper, but have found what is probably a later variation of that figure in Stepp\\'s dissertation, which lists the value \"normal\" for the first 2 classes and \"irrelevant\" for the latter 2 classes.  I believe that \"irrelevant\" is used here as a synonym for \"not-applicable\", \"dna\", and \"does-not-apply\".  I believe that there is a mis-print in the figure he read in their PAMI-83 article.\\r\\n \\r\\nI have checked over each attribute value in this database.  It corresponds exactly with the copies listed in both Stepp\\'s and Fisher\\'s dissertations.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '    1. date:\\t\\tapril,may,june,july,august,september,october,?.\\r\\n    2. plant-stand:\\tnormal,lt-normal,?.\\r\\n    3. precip:\\t\\tlt-norm,norm,gt-norm,?.\\r\\n    4. temp:\\t\\tlt-norm,norm,gt-norm,?.\\r\\n    5. hail:\\t\\tyes,no,?.\\r\\n    6. crop-hist:\\tdiff-lst-year,same-lst-yr,same-lst-two-yrs,\\r\\n                        same-lst-sev-yrs,?.\\r\\n    7. area-damaged:\\tscattered,low-areas,upper-areas,whole-field,?.\\r\\n    8. severity:\\tminor,pot-severe,severe,?.\\r\\n    9. seed-tmt:\\tnone,fungicide,other,?.\\r\\n   10. germination:\\t90-100%,80-89%,lt-80%,?.\\r\\n   11. plant-growth:\\tnorm,abnorm,?.\\r\\n   12. leaves:\\t\\tnorm,abnorm.\\r\\n   13. leafspots-halo:\\tabsent,yellow-halos,no-yellow-halos,?.\\r\\n   14. leafspots-marg:\\tw-s-marg,no-w-s-marg,dna,?.\\r\\n   15. leafspot-size:\\tlt-1/8,gt-1/8,dna,?.\\r\\n   16. leaf-shread:\\tabsent,present,?.\\r\\n   17. leaf-malf:\\tabsent,present,?.\\r\\n   18. leaf-mild:\\tabsent,upper-surf,lower-surf,?.\\r\\n   19. stem:\\t\\tnorm,abnorm,?.\\r\\n   20. lodging:    \\tyes,no,?.\\r\\n   21. stem-cankers:\\tabsent,below-soil,above-soil,above-sec-nde,?.\\r\\n   22. canker-lesion:\\tdna,brown,dk-brown-blk,tan,?.\\r\\n   23. fruiting-bodies:\\tabsent,present,?.\\r\\n   24. external decay:\\tabsent,firm-and-dry,watery,?.\\r\\n   25. mycelium:\\tabsent,present,?.\\r\\n   26. int-discolor:\\tnone,brown,black,?.\\r\\n   27. sclerotia:\\tabsent,present,?.\\r\\n   28. fruit-pods:\\tnorm,diseased,few-present,dna,?.\\r\\n   29. fruit spots:\\tabsent,colored,brown-w/blk-specks,distort,dna,?.\\r\\n   30. seed:\\t\\tnorm,abnorm,?.\\r\\n   31. mold-growth:\\tabsent,present,?.\\r\\n   32. seed-discolor:\\tabsent,present,?.\\r\\n   33. seed-size:\\tnorm,lt-norm,?.\\r\\n   34. shriveling:\\tabsent,present,?.\\r\\n   35. roots:\\t\\tnorm,rotted,galls-cysts,?.', 'citation': None}}\n",
      "               name     role         type demographic description units  \\\n",
      "0              date  Feature  Categorical        None        None  None   \n",
      "1       plant-stand  Feature  Categorical        None        None  None   \n",
      "2            precip  Feature  Categorical        None        None  None   \n",
      "3              temp  Feature  Categorical        None        None  None   \n",
      "4              hail  Feature  Categorical        None        None  None   \n",
      "5         crop-hist  Feature  Categorical        None        None  None   \n",
      "6      area-damaged  Feature  Categorical        None        None  None   \n",
      "7          severity  Feature  Categorical        None        None  None   \n",
      "8          seed-tmt  Feature  Categorical        None        None  None   \n",
      "9       germination  Feature  Categorical        None        None  None   \n",
      "10     plant-growth  Feature  Categorical        None        None  None   \n",
      "11           leaves  Feature  Categorical        None        None  None   \n",
      "12   leafspots-halo  Feature  Categorical        None        None  None   \n",
      "13   leafspots-marg  Feature  Categorical        None        None  None   \n",
      "14    leafspot-size  Feature  Categorical        None        None  None   \n",
      "15      leaf-shread  Feature  Categorical        None        None  None   \n",
      "16        leaf-malf  Feature  Categorical        None        None  None   \n",
      "17        leaf-mild  Feature  Categorical        None        None  None   \n",
      "18             stem  Feature  Categorical        None        None  None   \n",
      "19          lodging  Feature  Categorical        None        None  None   \n",
      "20     stem-cankers  Feature  Categorical        None        None  None   \n",
      "21    canker-lesion  Feature  Categorical        None        None  None   \n",
      "22  fruiting-bodies  Feature  Categorical        None        None  None   \n",
      "23   external-decay  Feature  Categorical        None        None  None   \n",
      "24         mycelium  Feature  Categorical        None        None  None   \n",
      "25     int-discolor  Feature  Categorical        None        None  None   \n",
      "26        sclerotia  Feature  Categorical        None        None  None   \n",
      "27       fruit-pods  Feature  Categorical        None        None  None   \n",
      "28      fruit-spots  Feature  Categorical        None        None  None   \n",
      "29             seed  Feature  Categorical        None        None  None   \n",
      "30      mold-growth  Feature  Categorical        None        None  None   \n",
      "31    seed-discolor  Feature  Categorical        None        None  None   \n",
      "32        seed-size  Feature  Categorical        None        None  None   \n",
      "33       shriveling  Feature  Categorical        None        None  None   \n",
      "34            roots  Feature  Categorical        None        None  None   \n",
      "35            class   Target  Categorical        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n",
      "32             no  \n",
      "33             no  \n",
      "34             no  \n",
      "35             no  \n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "soybean_small = fetch_ucirepo(id=91) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X_soy = soybean_small.data.features \n",
    "y_soy = soybean_small.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(soybean_small.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(soybean_small.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce8b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4762456b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 11 (660979022.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.x = x\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 11\n"
     ]
    }
   ],
   "source": [
    "#BMM - EM\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "class BernoulliMixture:\n",
    "    \n",
    "    def __init__(self, n_components, max_iter, tol=1e-3):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "    \n",
    "    def fit(self, x):\n",
    "    self.x = x\n",
    "    self.init_params()\n",
    "    self.sk = np.zeros((self.n_components, self.x.shape[1]))\n",
    "    self.pi_k = np.zeros(self.n_components)\n",
    "    log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "    self.old_logL = self.get_log_likelihood(log_bernoullis)\n",
    "    \n",
    "    # Initially remember parameters after initialization\n",
    "    self.remember_params()\n",
    "\n",
    "    for step in range(self.max_iter):\n",
    "        indices = np.random.choice(self.n_samples, self.batch_size, replace=False)\n",
    "        x_batch = self.x[indices]\n",
    "        log_bernoullis_batch = self.get_log_bernoullis(x_batch)\n",
    "\n",
    "        # E-Step: Calculate responsibilities for the batch\n",
    "        gamma_batch = self.get_responsibilities(log_bernoullis_batch)\n",
    "\n",
    "        # Simulation of latent variables (gamma)\n",
    "        latent_samples = np.array([np.random.choice(self.n_components, p=gamma) for gamma in gamma_batch])\n",
    "\n",
    "        # Convert latent_samples to a format suitable for updating sk\n",
    "        latent_samples_onehot = np.zeros((self.batch_size, self.n_components))\n",
    "        latent_samples_onehot[np.arange(self.batch_size), latent_samples] = 1\n",
    "\n",
    "        # Stochastic Approximation: Update the sufficient statistics\n",
    "        step_size = 1.0 / (step + 1)\n",
    "        self.sk = (1 - step_size) * self.sk + step_size * np.dot(latent_samples_onehot.T, x_batch) / self.batch_size\n",
    "        self.pi_k = (1 - step_size) * self.pi_k + step_size * np.mean(latent_samples_onehot, axis=0)\n",
    "\n",
    "        # Remember old parameters before updating\n",
    "        self.remember_params()\n",
    "\n",
    "        # M-Step: Update parameters based on sufficient statistics\n",
    "        self.mu = self.sk / np.sum(self.sk, axis=1, keepdims=True)\n",
    "        self.pi = self.pi_k / np.sum(self.pi_k)\n",
    "\n",
    "        # Compute new log_likelihood:\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "        if np.isnan(self.logL):\n",
    "            self.reset_params()\n",
    "            print(self.logL)\n",
    "            break\n",
    "\n",
    "\n",
    "    def remember_params(self):\n",
    "    self.old_mu = self.mu.copy() if hasattr(self, 'mu') else None\n",
    "    self.old_pi = self.pi.copy() if hasattr(self, 'pi') else None\n",
    "\n",
    "    def reset_params(self):\n",
    "        if hasattr(self, 'old_mu') and self.old_mu is not None:\n",
    "            self.mu = self.old_mu.copy()\n",
    "        if hasattr(self, 'old_pi') and self.old_pi is not None:\n",
    "            self.pi = self.old_pi.copy()\n",
    "        # Ensure the rest of the reset logic uses the existing parameters if old parameters were not set\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "\n",
    "    \n",
    "    def init_params(self):\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        self.n_features = self.x.shape[1]\n",
    "        self.pi = 1/self.n_components * np.ones(self.n_components)\n",
    "        self.mu = np.random.RandomState(seed=0).uniform(low=0.25, high=0.75, size=(self.n_components, self.n_features))\n",
    "        self.normalize_mu()\n",
    "    \n",
    "    def normalize_mu(self):\n",
    "        sum_over_features = np.sum(self.mu, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            self.mu[k,:] /= sum_over_features[k]\n",
    "            \n",
    "    def get_responsibilities(self, log_bernoullis):\n",
    "        gamma = np.zeros(shape=(log_bernoullis.shape[0], self.n_components))\n",
    "        Z =  logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            gamma[:, k] = np.exp(np.log(self.pi[k]) + log_bernoullis[:,k] - Z)\n",
    "        return gamma\n",
    "        \n",
    "    def get_log_bernoullis(self, x):\n",
    "        log_bernoullis = self.get_save_single(x, self.mu)\n",
    "        log_bernoullis += self.get_save_single(1-x, 1-self.mu)\n",
    "        return log_bernoullis\n",
    "    \n",
    "    def get_save_single(self, x, mu):\n",
    "        mu_place = np.where(np.max(mu, axis=0) <= 1e-15, 1e-15, mu)\n",
    "        return np.tensordot(x, np.log(mu_place), (1,1))\n",
    "        \n",
    "    def get_Neff(self):\n",
    "        self.Neff = np.sum(self.gamma, axis=0)\n",
    "    \n",
    "    def get_mu(self):\n",
    "        self.mu = np.einsum('ik,id -> kd', self.gamma, self.x) / self.Neff[:,None] \n",
    "        \n",
    "    def get_pi(self):\n",
    "        self.pi = self.Neff / self.n_samples\n",
    "    \n",
    "    def predict(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        gamma = self.get_responsibilities(log_bernoullis)\n",
    "        return np.argmax(gamma, axis=1)\n",
    "        \n",
    "    def get_sample_log_likelihood(self, log_bernoullis):\n",
    "        return logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "    \n",
    "    def get_log_likelihood(self, log_bernoullis):\n",
    "        return np.mean(self.get_sample_log_likelihood(log_bernoullis))\n",
    "        \n",
    "    def score(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_log_likelihood(log_bernoullis)\n",
    "    \n",
    "    def score_samples(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_sample_log_likelihood(log_bernoullis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1370133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAEM\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "class BernoulliMixtureSAEM:\n",
    "    def __init__(self, n_components, max_iter=100, batch_size=10):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.pi = None\n",
    "        self.mu = None\n",
    "\n",
    "    def init_params(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.mu = np.random.rand(self.n_components, n_features)\n",
    "        self.pi = np.ones(self.n_components) / self.n_components\n",
    "\n",
    "    def get_log_bernoullis(self, X):\n",
    "        # Bernoulli log probability calculations\n",
    "        log_mu = np.log(self.mu.clip(min=1e-15))\n",
    "        log_mu_neg = np.log((1 - self.mu).clip(min=1e-15))\n",
    "        return np.dot(X, log_mu.T) + np.dot(1 - X, log_mu_neg.T)\n",
    "\n",
    "    def get_responsibilities(self, log_bernoullis):\n",
    "        weighted_log_probs = log_bernoullis + np.log(self.pi)\n",
    "        log_sum = logsumexp(weighted_log_probs, axis=1, keepdims=True)\n",
    "        return np.exp(weighted_log_probs - log_sum)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.init_params(X)\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        for step in range(self.max_iter):\n",
    "            indices = np.random.choice(n_samples, self.batch_size, replace=False)\n",
    "            X_batch = X[indices]\n",
    "\n",
    "            log_bernoullis_batch = self.get_log_bernoullis(X_batch)\n",
    "            gamma = self.get_responsibilities(log_bernoullis_batch)\n",
    "\n",
    "            # Update step for mu and pi\n",
    "            gamma_sum = gamma.sum(axis=0)\n",
    "            self.mu = (gamma.T @ X_batch + self.mu * self.batch_size) / (gamma_sum[:, None] + self.batch_size)\n",
    "            self.pi = (gamma_sum / self.batch_size + self.pi * self.batch_size) / (self.batch_size + self.batch_size)\n",
    "\n",
    "    def predict(self, X):\n",
    "        log_bernoullis = self.get_log_bernoullis(X)\n",
    "        gamma = self.get_responsibilities(log_bernoullis)\n",
    "        return np.argmax(gamma, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1d1c36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1]\n",
      "Cluster centers (mu parameters):\n",
      "[[4.95975346e-01 8.58874002e-01 7.14049119e-01 9.50392060e-01\n",
      "  5.29056160e-01 9.79132103e-01 1.05741280e-02 4.87740659e-01\n",
      "  9.74325073e-01 9.38236289e-01 5.15958914e-02 7.53812128e-01\n",
      "  6.20036626e-01 7.77711298e-01 7.26379343e-01 9.56513482e-01\n",
      "  6.88606818e-02 5.21416954e-01 8.78408721e-01 7.77037638e-01\n",
      "  2.04489279e-01 7.17924015e-01 8.56512349e-01 5.23707958e-01\n",
      "  6.75940013e-01 8.75693551e-01 4.32607483e-01 6.19614816e-02\n",
      "  4.13314949e-01 4.32884948e-01 3.06037637e-01 1.95669370e-01\n",
      "  6.51525913e-01 5.00573565e-01 9.37197718e-01 9.29361539e-01\n",
      "  3.02807337e-01 6.93988059e-01 2.29117174e-01 2.04343988e-01\n",
      "  7.85112987e-01 3.02782434e-02 3.08254902e-01 6.45801267e-01\n",
      "  2.64989163e-01 3.67378296e-01 1.62182855e-02 5.62557196e-01\n",
      "  2.15629114e-01 5.61472042e-01 4.23663595e-01 1.84272998e-01\n",
      "  6.42196235e-01 8.71661296e-01 9.98167501e-01 1.19495639e-01\n",
      "  7.76121163e-01 3.61673329e-01 9.24459594e-01 8.81778649e-01\n",
      "  1.10863581e-01 5.25669670e-01 2.86908110e-01 4.87282060e-01\n",
      "  4.84739167e-01 7.83605577e-01 1.05789523e-01 2.35611421e-01\n",
      "  7.23441669e-01 2.42742370e-01 8.89602181e-01 9.54696119e-01]\n",
      " [2.61232550e-01 2.08585835e-01 3.27979836e-01 1.35037524e-01\n",
      "  6.71642560e-02 5.23158318e-21 9.81017027e-21 9.67087703e-02\n",
      "  9.03291230e-01 1.44456705e-20 2.89272802e-01 7.10727198e-01\n",
      "  6.78227538e-01 3.21772462e-01 2.86394018e-21 8.14216195e-01\n",
      "  1.85783805e-01 2.54811961e-01 2.12670428e-01 1.17518934e-01\n",
      "  4.14998676e-01 2.07221544e-20 9.99959281e-01 3.11864108e-20\n",
      "  4.07191958e-05 3.04443600e-01 6.95556400e-01 6.74898876e-01\n",
      "  3.25101124e-01 2.53320809e-01 2.79670109e-01 4.67009082e-01\n",
      "  1.00000000e+00 2.71863081e-01 7.28136919e-01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00 8.53922266e-01 1.46077734e-01\n",
      "  1.82695725e-20 7.03216932e-01 2.96783068e-01 2.18304758e-20\n",
      "  4.02185967e-20 3.39027337e-01 6.60972663e-01 2.51911841e-20\n",
      "  1.00000000e+00 3.64016438e-20 5.71897628e-01 4.28102372e-01\n",
      "  8.01968408e-01 1.98031592e-01 1.00000000e+00 2.29622996e-20\n",
      "  1.00000000e+00 1.53422973e-20 2.23385078e-20 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00 2.92927868e-01 7.07072132e-01]\n",
      " [3.66924928e-16 3.77659813e-16 4.05979503e-16 1.81730487e-01\n",
      "  1.24469657e-01 2.71713090e-01 4.22086765e-01 1.00000000e+00\n",
      "  6.78704122e-16 4.35742292e-01 2.40059725e-16 5.64257708e-01\n",
      "  4.58281382e-16 8.39516185e-01 1.60483815e-01 6.74519543e-01\n",
      "  3.25480457e-01 5.91413803e-02 3.24375369e-01 1.85585646e-01\n",
      "  4.30897605e-01 3.05200865e-01 2.59056843e-01 1.48542152e-01\n",
      "  2.87200140e-01 8.99466330e-01 1.00533670e-01 3.54933476e-01\n",
      "  6.45066524e-01 4.55812882e-01 2.66318276e-01 2.77868842e-01\n",
      "  1.00000000e+00 8.33674662e-16 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00 5.25593350e-01 4.74406650e-01\n",
      "  4.35742292e-01 6.91522849e-16 1.25503247e-16 5.64257708e-01\n",
      "  2.06770586e-01 3.57487122e-01 1.81379900e-19 4.35742292e-01\n",
      "  4.35742292e-01 5.64257708e-01 4.35742292e-01 5.64257708e-01\n",
      "  1.00000000e+00 4.68051663e-16 5.64257708e-01 4.35742292e-01\n",
      "  5.64257708e-01 4.35742292e-01 1.00000000e+00 7.08296837e-16\n",
      "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00 1.00000000e+00 3.63914911e-16]\n",
      " [8.42865650e-01 2.84845309e-02 6.30082072e-01 4.82619981e-01\n",
      "  5.86378526e-01 1.17207492e-01 7.68932957e-01 8.36390568e-01\n",
      "  4.01165082e-01 4.82739661e-01 3.39658255e-01 6.51024935e-01\n",
      "  2.89134467e-01 2.31687279e-01 4.19309910e-01 3.31337037e-01\n",
      "  4.21971171e-01 7.70641814e-01 8.42528282e-01 8.96000572e-01\n",
      "  3.99428796e-01 3.83367284e-01 1.03701322e-01 6.45780498e-01\n",
      "  9.68155211e-01 7.73606223e-01 1.27288234e-01 9.29628065e-01\n",
      "  9.26049879e-01 1.40577301e-02 5.34917986e-01 2.14360680e-01\n",
      "  2.18335484e-01 6.34706150e-01 9.99239089e-01 8.14396450e-02\n",
      "  9.52030638e-03 3.46383498e-01 5.18793911e-02 4.29709669e-02\n",
      "  3.18353917e-01 6.62699207e-01 3.95135748e-01 2.92720313e-01\n",
      "  1.53916778e-01 3.73588521e-01 5.48331784e-01 1.82376906e-01\n",
      "  7.98234675e-01 7.94156693e-01 7.57614677e-01 1.76498134e-01\n",
      "  6.03745517e-01 4.87712200e-01 8.04002241e-01 4.25979871e-01\n",
      "  2.56012225e-01 1.68484837e-02 1.04135702e-01 6.48736812e-01\n",
      "  5.92379006e-01 1.35874990e-01 3.39763870e-01 3.49754350e-02\n",
      "  3.47220771e-01 6.26911204e-01 2.06603819e-01 7.80765654e-01\n",
      "  4.26377661e-01 4.47034292e-01 9.74592754e-01 2.28158893e-01]]\n",
      "FMI (BMM): 0.7077599977518827\n",
      "ARI (BMM): 0.5006928406466513\n",
      "NMI (BMM): 0.669413786240395\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X_soy)\n",
    "\n",
    "model = BernoulliMixtureSAEM(n_components=4, max_iter=100, batch_size=10)\n",
    "model.fit(X_encoded)\n",
    "clusters = model.predict(X_encoded)\n",
    "print(clusters)\n",
    "\n",
    "print(\"Cluster centers (mu parameters):\")\n",
    "print(model.mu)\n",
    "\n",
    "fmi_bmm = fowlkes_mallows_score(y_series, clusters)\n",
    "ari_bmm = adjusted_rand_score(y_series, clusters)\n",
    "nmi_bmm = normalized_mutual_info_score(y_series, clusters)\n",
    "\n",
    "print(\"FMI (BMM):\", fmi_bmm)\n",
    "print(\"ARI (BMM):\", ari_bmm)\n",
    "print(\"NMI (BMM):\", nmi_bmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc2abcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMI (KModes): 1.0\n",
      "ARI (KModes): 1.0\n",
      "NMI (KModes): 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "from kmodes.kmodes import KModes\n",
    "\n",
    "# Perform KModes clustering\n",
    "km = KModes(n_clusters=4)  \n",
    "clusters_km = km.fit_predict(X_soy)\n",
    "y_series = y_soy.squeeze()\n",
    "# Compute FMI\n",
    "fmi_km = fowlkes_mallows_score(y_series, clusters_km)\n",
    "print(\"FMI (KModes):\", fmi_km)\n",
    "\n",
    "# Compute ARI\n",
    "ari_km = adjusted_rand_score(y_series, clusters_km)\n",
    "print(\"ARI (KModes):\", ari_km)\n",
    "\n",
    "# Compute NMI\n",
    "nmi_km = normalized_mutual_info_score(y_series, clusters_km)\n",
    "print(\"NMI (KModes):\", nmi_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bff3d5",
   "metadata": {},
   "source": [
    "$\\textbf{Report}$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc922aaf",
   "metadata": {},
   "source": [
    "There is a big gap between the BMM SAEM and K-Mode Results. \n",
    "This might be because K-Mode is designed for categorical data, which is the type of data in the soybean dataset.\n",
    "The dataset had to be preprocessed and one-hot encoded before performing BMM SAEM on it. Therefore, while K-Mode\n",
    "could naturally identify the patterns in the data, transorming the categorical data to binary format with one-hot encoding could have diluted some relationships. \n",
    "\n",
    "Additionally, the randomness in SAEM can lead to different optima, and can change the results. However, trying out 3,5,6,and 8\n",
    "number of components lead to lower or around the same result. Furthermore, FMI  being 1 in K-Modes shows that it identified all true positive pairs without any false positives or negatives. For ARI and NMI, they might be lower as they are sensitive to matching clusters to the ground truth. So, a lower score may mean that the BMM clusters have overlaps. And as ARI and NMI are more focused on mathcing the clusters versus the ground-truth clusters and FMI focuses more on the mean of precision and recal rather than overall cluster comparison, FMI has a higher value because many pairs of points that belong together are still in the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65e40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
